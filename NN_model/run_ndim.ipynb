{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pmdarima import auto_arima\n",
    "from config import architecture, seq_length, num_epochs, learning_rate, wandb_config, model\n",
    "from preprocessing import stock_df, features_df, labels\n",
    "\n",
    "class StockPredictionModule(pl.LightningModule):\n",
    "    def __init__(self, model, label_scaler, train_loader, val_loader, test_loader, test_dates):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.label_scaler = label_scaler\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.test_dates = test_dates\n",
    "        self.criterion = nn.MSELoss()\n",
    "        # self.criterion = torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean', label_smoothing=0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        predictions, actuals = [], []\n",
    "        for seqs, labels in self.test_loader:\n",
    "            seqs, labels = seqs.to(self.device), labels.to(self.device)\n",
    "            output = self(seqs)\n",
    "            predictions.extend(output.view(-1).detach().cpu().numpy())\n",
    "            actuals.extend(labels.view(-1).detach().cpu().numpy())\n",
    "\n",
    "        len_test_set = len(predictions)\n",
    "\n",
    "        predictions_rescaled = list(self.label_scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten())\n",
    "        actuals_rescaled = list(self.label_scaler.inverse_transform(np.array(actuals).reshape(-1, 1)).flatten())\n",
    "        baseline_rescaled = [actuals_rescaled[0]] + actuals_rescaled[:-1]\n",
    "\n",
    "        \"\"\"\n",
    "        # Test gemacht: actuals ist um eins zu weit nach rechts verschoben, verglichen mit dem selben Index der Preise im stock_df Dataframe. \n",
    "        # Daher verschieben wir es hier um eins nach links\n",
    "        actuals_rescaled = actuals_rescaled[1:]\n",
    "        predictions_rescaled = predictions_rescaled[1:]\n",
    "        baseline_rescaled = baseline_rescaled[1:]\n",
    "        \"\"\"\n",
    "        \n",
    "        actual_closing_prices = stock_df['Close'].values[-(len_test_set):]\n",
    "\n",
    "        actual_prices = [actual_closing_prices[i] * actuals_rescaled[i] for i in range(len(actuals_rescaled))]\n",
    "        prediction_prices = [actual_closing_prices[i] * predictions_rescaled[i] for i in range(len(actuals_rescaled))]\n",
    "        baseline_prices = [actual_prices[0]] + actual_prices[:-1]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 7))\n",
    "        ax.plot(self.test_dates[-200:], actual_prices[-200:], label='Actual Price', color='black', linestyle='-')\n",
    "        ax.plot(self.test_dates[-200:], prediction_prices[-200:], label='Predicted Price', color='green', linestyle='-')\n",
    "        ax.plot(self.test_dates[-200:], baseline_prices[-200:], label='Baseline', color='blue', linestyle='-')\n",
    "        ax.set_title('Stock Price Prediction')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Stock Price')\n",
    "        ax.legend()\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.plot()\n",
    "        plt.show()\n",
    "        filename = \"plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Stock Price Prediction\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "        net_abs_dev = torch.tensor([abs(predictions_rescaled[i] - actuals_rescaled[i]) for i in range(len(actuals_rescaled))])\n",
    "        baseline_abs_dev = torch.tensor([abs(baseline_rescaled[i] - actuals_rescaled[i]) for i in range(len(actuals_rescaled))])\n",
    "        diff_pos = torch.relu(baseline_abs_dev - net_abs_dev).reshape(-1).tolist()\n",
    "        diff_min = (-torch.relu(net_abs_dev - baseline_abs_dev)).reshape(-1).tolist()\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.set_title('Model vs baseline performance comparison on test samples')\n",
    "        ax.hlines(0, xmin=0, xmax=len(actuals_rescaled), linestyles='dashed', colors='black')\n",
    "        ax.bar(list(range(len(actuals_rescaled))), diff_pos, color='g', label='Model Wins', width=1.0)\n",
    "        ax.bar(list(range(len(actuals_rescaled))), diff_min, color='r', label='Baseline Wins', width=1.0)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('Test Sample Index')\n",
    "        ax.set_ylabel('Difference in Absolute Deviation')\n",
    "        plt.show()\n",
    "        filename = \"comparison_plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Model vs Baseline Performance Comparison\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "        model_actual_dev = torch.tensor([predictions_rescaled[i] - actuals_rescaled[i] for i in range(len(actuals_rescaled))])\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.set_title('Model deviations from actuals')\n",
    "        ax.hlines(0, xmin=0, xmax=len(actuals_rescaled), linestyles='dashed', colors='black')\n",
    "        ax.bar(list(range(len(actuals_rescaled))), model_actual_dev, color='g', label='Model Wins', width=1.0)\n",
    "        ax.set_xlabel('Test Sample Index')\n",
    "        ax.set_ylabel('Deviation from actuals')\n",
    "        plt.show()\n",
    "        filename = \"comparison_plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Model deviations from actuals\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "        baseline_actual_dev = torch.tensor([baseline_rescaled[i] - actuals_rescaled[i] for i in range(len(actuals_rescaled))])\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.set_title('Baseline deviations from actuals')\n",
    "        ax.hlines(0, xmin=0, xmax=len(actuals_rescaled), linestyles='dashed', colors='black')\n",
    "        ax.bar(list(range(len(actuals_rescaled))), baseline_actual_dev, color='b', label='Baseline Wins', width=1.0)\n",
    "        ax.set_xlabel('Test Sample Index')\n",
    "        ax.set_ylabel('Deviation from actuals')\n",
    "        plt.show()\n",
    "        filename = \"comparison_plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Baseline deviations from actuals\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "        actual_prices = np.array(actual_prices)\n",
    "        prediction_prices = np.array(prediction_prices)\n",
    "        baseline_prices = np.array(baseline_prices)\n",
    "\n",
    "        model_mse = mean_squared_error(actual_prices, prediction_prices)\n",
    "        model_rmse = np.sqrt(model_mse)\n",
    "        model_mae = mean_absolute_error(actual_prices, prediction_prices)\n",
    "        model_r2 = r2_score(actual_prices, prediction_prices)\n",
    "        model_mape = np.mean(np.abs((actual_prices - prediction_prices) / actual_prices))\n",
    "        \n",
    "        baseline_mse = mean_squared_error(actual_prices, baseline_prices)\n",
    "        baseline_rmse = np.sqrt(baseline_mse)\n",
    "        baseline_mae = mean_absolute_error(actual_prices, baseline_prices)\n",
    "        baseline_r2 = r2_score(actual_prices, baseline_prices)\n",
    "        baseline_mape = np.mean(np.abs((actual_prices - baseline_prices) / (actual_prices + 1e-8)))\n",
    "\n",
    "        model_metrics = {\n",
    "            \"mse\": model_mse,\n",
    "            \"rmse\": model_rmse,\n",
    "            \"mae\": model_mae,\n",
    "            \"mape\": model_mape,\n",
    "            \"r2\": model_r2,\n",
    "        }\n",
    "\n",
    "        baseline_metrics = {\n",
    "            \"mse\": baseline_mse,\n",
    "            \"rmse\": baseline_rmse,\n",
    "            \"mae\": baseline_mae,\n",
    "            \"mape\": baseline_mape,\n",
    "            \"r2\": baseline_r2,\n",
    "        }\n",
    "\n",
    "        model_baseline_performance_metrics = {\n",
    "            \"mse\": round((baseline_mse / model_mse - 1) * 100, 2),\n",
    "            \"rmse\": round((baseline_rmse / model_rmse - 1) * 100, 2),\n",
    "            \"mae\": round((baseline_mae / model_mae - 1) * 100, 2),\n",
    "            \"mape\": round((baseline_mape / model_mape - 1) * 100, 2),\n",
    "            \"r2\": round((model_r2 / baseline_r2 - 1) * 100, 2),\n",
    "        }\n",
    "\n",
    "        metrics_table = wandb.Table(columns=[\"metric\", \"model\", \"baseline\", \"model-baseline performance comparison [%]\"])\n",
    "        for metric in model_metrics.keys():\n",
    "            metrics_table.add_data(metric, model_metrics[metric], baseline_metrics[metric], model_baseline_performance_metrics[metric])\n",
    "        wandb.log({\"metrics\": metrics_table})\n",
    "\n",
    "\n",
    "def create_sequences(data, labels):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = labels[i + seq_length - 1]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    total_length = len(features_df)\n",
    "    split_idx = int(total_length * 0.8) + seq_length\n",
    "    val_test_idx = int(total_length * 0.9) + seq_length\n",
    "\n",
    "    train_df = features_df.iloc[:split_idx]\n",
    "    val_df = features_df.iloc[split_idx:val_test_idx]\n",
    "    test_df = features_df.iloc[val_test_idx:]\n",
    "\n",
    "    train_labels = labels[:split_idx]\n",
    "    val_labels = labels[split_idx:val_test_idx]\n",
    "    test_labels = labels[val_test_idx:]\n",
    "\n",
    "    # Normalizing each feature individually\n",
    "    feature_scaler = {}\n",
    "    train_normalized = train_df.copy()\n",
    "    val_normalized = val_df.copy()\n",
    "    test_normalized = test_df.copy()\n",
    "\n",
    "    for column in train_df.columns:\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        train_normalized[column] = scaler.fit_transform(train_df[column].values.reshape(-1, 1)).flatten()\n",
    "        val_normalized[column] = scaler.transform(val_df[column].values.reshape(-1, 1)).flatten()\n",
    "        test_normalized[column] = scaler.transform(test_df[column].values.reshape(-1, 1)).flatten()\n",
    "        feature_scaler[column] = scaler\n",
    "\n",
    "    label_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_labels_scaled = label_scaler.fit_transform(train_labels.reshape(-1, 1))\n",
    "    val_labels_scaled = label_scaler.transform(val_labels.reshape(-1, 1))\n",
    "    test_labels_scaled = label_scaler.transform(test_labels.reshape(-1, 1))\n",
    "\n",
    "    X_train, y_train = create_sequences(train_normalized.values, train_labels_scaled.flatten())\n",
    "    X_val, y_val = create_sequences(val_normalized.values, val_labels_scaled.flatten())\n",
    "    X_test, y_test = create_sequences(test_normalized.values, test_labels_scaled.flatten())\n",
    "\n",
    "    test_dates = features_df.index[-(len(X_test) + seq_length):].tolist()\n",
    "    test_dates = test_dates[seq_length:]\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train)), batch_size=64, shuffle=False, \n",
    "                                               num_workers=15, persistent_workers=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val)), batch_size=64, shuffle=False, \n",
    "                                             num_workers=15, persistent_workers=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test)), batch_size=64, shuffle=False, \n",
    "                                              num_workers=15, persistent_workers=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, label_scaler, test_dates\n",
    "\n",
    "def main():\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "    wandb_logger = WandbLogger(project=\"RNN_single_step_forecasts\", log_model=\"all\", config=wandb_config)\n",
    "    train_loader, val_loader, test_loader, label_scaler, test_dates = load_data()\n",
    "    \n",
    "    module = StockPredictionModule(model=model, label_scaler=label_scaler,\n",
    "                                   train_loader=train_loader, val_loader=val_loader, test_loader=test_loader, test_dates = test_dates)\n",
    "\n",
    "    # Device agnostic initialization\n",
    "    if torch.cuda.is_available():   # Check for GPU availability\n",
    "        accelerator = \"gpu\"\n",
    "        devices = 1\n",
    "    elif hasattr(torch, 'has_mps') and torch.backends.mps.is_built():  # Check for MPS availability (Apple Silicon)\n",
    "        accelerator = \"mps\"\n",
    "        devices = 1\n",
    "    else:\n",
    "        accelerator = None  # Defaults to CPU\n",
    "        devices = None  # Ignored for CPU\n",
    "\n",
    "    trainer = Trainer(max_epochs=num_epochs, logger=wandb_logger, accelerator=accelerator, devices=devices, enable_checkpointing=True)\n",
    "    trainer.fit(module, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    trainer.test(dataloaders=test_loader, ckpt_path=\"best\")\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install optuna\n",
    "\n",
    "# Hyperparamter tuning\n",
    "\n",
    "import optuna\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 16, 128)\n",
    "\n",
    "    # Update model config\n",
    "    model_config.update({\n",
    "        \"hidden_layer_size\": hidden_size,\n",
    "        \"num_layers\": num_layers\n",
    "    })\n",
    "\n",
    "    # Create the model with new hyperparameters\n",
    "    model = RNNModel(**model_config)\n",
    "\n",
    "    # Setup data\n",
    "    train_loader, val_loader, _, _, _, _, _ = load_data()\n",
    "\n",
    "    # Create the PyTorch Lightning module\n",
    "    pl_module = StockPredictionModule(model=model, optimizer=torch.optim.Adam, learning_rate=learning_rate)\n",
    "\n",
    "    # Trainer setup with Early Stopping\n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        checkpoint_callback=False,\n",
    "        max_epochs=50,\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "        progress_bar_refresh_rate=0\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    trainer.fit(pl_module, train_loader, val_loader)\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_result = trainer.validate(pl_module, val_dataloaders=val_loader, verbose=False)\n",
    "    val_loss = val_result[0]['val_loss']\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best hyperparameters: \", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import stock_df, labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import columns\n",
    "print(str(columns.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
