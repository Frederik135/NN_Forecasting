{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from config import num_epochs, learning_rate, wandb_config, model\n",
    "from preprocessing import stock_df\n",
    "from preprocessing import train_loader, val_loader, test_loader, label_scaler, test_dates, auto_arima_model\n",
    "\n",
    "class StockPredictionModule(pl.LightningModule):\n",
    "    def __init__(self, model, label_scaler, train_loader, val_loader, test_loader, test_dates):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.label_scaler = label_scaler\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.test_dates = test_dates\n",
    "        self.criterion = nn.MSELoss()\n",
    "        # self.criterion = torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean', label_smoothing=0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        predictions, actuals = [], []\n",
    "        for seqs, labels in self.test_loader:\n",
    "            seqs, labels = seqs.to(self.device), labels.to(self.device)\n",
    "            output = self(seqs)\n",
    "            predictions.extend(output.view(-1).detach().cpu().numpy())\n",
    "            actuals.extend(labels.view(-1).detach().cpu().numpy())\n",
    "\n",
    "        predictions_rescaled = list(self.label_scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten())\n",
    "        actuals_rescaled = list(self.label_scaler.inverse_transform(np.array(actuals).reshape(-1, 1)).flatten())\n",
    "        baseline_rescaled = [actuals_rescaled[0]] + actuals_rescaled[:-1]\n",
    "        arima_predictions = auto_arima_model.predict(n_periods=len(actuals_rescaled))\n",
    "        baseline_constant = [1.0] * len(predictions_rescaled)\n",
    "\n",
    "        len_test_set = len(predictions)\n",
    "        actual_closing_prices = stock_df['Close'].values[-(len_test_set):]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 7))\n",
    "        ax.plot(test_dates[-200:], actuals_rescaled[-200:], label='Actual Relative Difference', color='black', linestyle='-')\n",
    "        ax.plot(test_dates[-200:], predictions_rescaled[-200:], label='Predicted Relative Difference', color='green', linestyle='-')\n",
    "        ax.plot(test_dates[-200:], baseline_rescaled[-200:], label='Baseline_1', color='darkblue', linestyle='-')\n",
    "        ax.plot(test_dates[-200:], baseline_constant[-200:], label='Baseline_2', color='steelblue', linestyle='-')\n",
    "        # ax.plot(test_dates[-100:], arima_predictions[-100:], label='Baseline', color='orange', linestyle='-') \n",
    "        ax.set_title('Relative Difference Prediction')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Relative Difference')\n",
    "        ax.legend()\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        filename = \"plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Relative Difference Prediction\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        # Use plotting with rebasing to visualize the predictions as prices\n",
    "        rebase_period = 30\n",
    "        predicted_prices = [actual_closing_prices[0]]\n",
    "        for i, relative_change in enumerate(predictions_rescaled[1:], 1):\n",
    "            if i % rebase_period == 0:\n",
    "                predicted_prices.append(actual_closing_prices[i])\n",
    "            else:\n",
    "                predicted_prices.append(predicted_prices[-1] * relative_change)\n",
    "        baseline_prices = [actual_closing_prices[0]] + list(actual_closing_prices[:-1])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 7))\n",
    "        ax.plot(test_dates, actual_closing_prices, label='Actual Price', color='black', linestyle='-')\n",
    "        ax.plot(test_dates, predicted_prices, label='Predicted Price', color='green', linestyle='-')\n",
    "        ax.plot(test_dates, baseline_prices, label='Baseline', color='blue', linestyle='-') \n",
    "        ax.set_title('Price predictions based on last price in validation set')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Stock Price')\n",
    "        ax.legend()\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        filename = \"plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Stock Price Prediction\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        # We use for the first value the actual closing price and then multiply the relative change for each following timestep\n",
    "        actual_prices = [actual_closing_prices[0]]\n",
    "        for i in range(1, len(actuals_rescaled)):\n",
    "            actual_prices.append(actual_prices[i-1] * actuals_rescaled[i])\n",
    "        prediction_prices = [actual_closing_prices[0]]\n",
    "        for i in range(1, len(predictions_rescaled)):\n",
    "            prediction_prices.append(prediction_prices[i-1] * predictions_rescaled[i])\n",
    "        baseline_prices = [actual_prices[0]] + actual_prices[:-1]\n",
    "        fig, ax = plt.subplots(figsize=(15, 7))\n",
    "        ax.plot(test_dates, actual_prices, label='Actual Price', color='black', linestyle='-')\n",
    "        ax.plot(test_dates, prediction_prices, label='Predicted Price', color='green', linestyle='-')\n",
    "        ax.plot(test_dates, baseline_prices, label='Baseline', color='blue', linestyle='-')\n",
    "        ax.set_title('Stock Price Prediction')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Stock Price')\n",
    "        ax.legend()\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        filename = \"plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Stock Price Prediction\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "        \"\"\"\n",
    "        \n",
    "        net_abs_dev = torch.tensor([abs(predictions_rescaled[i] - actuals_rescaled[i]) for i in range(len(actuals_rescaled))])\n",
    "        baseline_abs_dev = torch.tensor([abs(baseline_rescaled[i] - actuals_rescaled[i]) for i in range(len(actuals_rescaled))])\n",
    "        diff_pos = torch.relu(baseline_abs_dev - net_abs_dev).reshape(-1).tolist()\n",
    "        diff_min = (-torch.relu(net_abs_dev - baseline_abs_dev)).reshape(-1).tolist()\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.set_title('Model vs baseline performance comparison on test samples')\n",
    "        ax.hlines(0, xmin=0, xmax=len(actuals_rescaled), linestyles='dashed', colors='black')\n",
    "        ax.bar(list(range(len(actuals_rescaled))), diff_pos, color='g', label='Model Wins', width=1.0)\n",
    "        ax.bar(list(range(len(actuals_rescaled))), diff_min, color='r', label='Baseline Wins', width=1.0)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('Test Sample Index')\n",
    "        ax.set_ylabel('Difference in Absolute Deviation')\n",
    "        plt.show()\n",
    "        filename = \"comparison_plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Model vs Baseline Performance Comparison\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "        model_actual_dev = torch.tensor([predictions_rescaled[i] - actuals_rescaled[i] for i in range(len(actuals_rescaled))])\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.set_title('Model deviations from actuals')\n",
    "        ax.hlines(0, xmin=0, xmax=len(actuals_rescaled), linestyles='dashed', colors='black')\n",
    "        ax.bar(list(range(len(actuals_rescaled))), model_actual_dev, color='g', label='Model Wins', width=1.0)\n",
    "        ax.set_xlabel('Test Sample Index')\n",
    "        ax.set_ylabel('Deviation from actuals')\n",
    "        plt.show()\n",
    "        filename = \"comparison_plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Model deviations from actuals\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "        baseline_actual_dev = torch.tensor([baseline_rescaled[i] - actuals_rescaled[i] for i in range(len(actuals_rescaled))])\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.set_title('Baseline deviations from actuals')\n",
    "        ax.hlines(0, xmin=0, xmax=len(actuals_rescaled), linestyles='dashed', colors='black')\n",
    "        ax.bar(list(range(len(actuals_rescaled))), baseline_actual_dev, color='b', label='Baseline Wins', width=1.0)\n",
    "        ax.set_xlabel('Test Sample Index')\n",
    "        ax.set_ylabel('Deviation from actuals')\n",
    "        plt.show()\n",
    "        filename = \"comparison_plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Baseline deviations from actuals\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "        arima_actual_dev = torch.tensor([arima_predictions[i] - actuals_rescaled[i] for i in range(len(actuals_rescaled))])\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.set_title('Arima deviations from actuals')\n",
    "        ax.hlines(0, xmin=0, xmax=len(actuals_rescaled), linestyles='dashed', colors='black')\n",
    "        ax.bar(list(range(len(actuals_rescaled))), arima_actual_dev, color='orange', width=1.0)\n",
    "        ax.set_xlabel('Test Sample Index')\n",
    "        ax.set_ylabel('Deviation from actuals')\n",
    "        plt.show()\n",
    "        filename = \"comparison_plot.png\"\n",
    "        fig.savefig(filename)\n",
    "        wandb.log({\"Arima deviations from actuals\": wandb.Image(filename)})\n",
    "        os.remove(filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "        actuals_rescaled = np.array(actuals_rescaled)\n",
    "        predictions_rescaled = np.array(predictions_rescaled)\n",
    "        baseline_rescaled = np.array(baseline_rescaled)\n",
    "        arima_predictions = np.array(arima_predictions)\n",
    "\n",
    "        model_mse = mean_squared_error(actuals_rescaled, predictions_rescaled)\n",
    "        model_rmse = np.sqrt(model_mse)\n",
    "        model_mae = mean_absolute_error(actuals_rescaled, predictions_rescaled)\n",
    "        model_r2 = r2_score(actuals_rescaled, predictions_rescaled)\n",
    "        model_mape = np.mean(np.abs((actuals_rescaled - predictions_rescaled) / (actuals_rescaled + 1e-8)))\n",
    "        \n",
    "        baseline_mse = mean_squared_error(actuals_rescaled, baseline_rescaled)\n",
    "        baseline_rmse = np.sqrt(baseline_mse)\n",
    "        baseline_mae = mean_absolute_error(actuals_rescaled, baseline_rescaled)\n",
    "        baseline_r2 = r2_score(actuals_rescaled, baseline_rescaled)\n",
    "        baseline_mape = np.mean(np.abs((actuals_rescaled - baseline_rescaled) / (actuals_rescaled + 1e-8)))\n",
    "\n",
    "        arima_mse = mean_squared_error(actuals_rescaled, arima_predictions)\n",
    "        arima_rmse = np.sqrt(arima_mse)\n",
    "        arima_mae = mean_absolute_error(actuals_rescaled, arima_predictions)\n",
    "        arima_r2 = r2_score(actuals_rescaled, arima_predictions)\n",
    "        arima_mape = np.mean(np.abs((actuals_rescaled - arima_predictions) / actuals_rescaled))\n",
    "\n",
    "        model_metrics = {\n",
    "            \"mse\": model_mse,\n",
    "            \"rmse\": model_rmse,\n",
    "            \"mae\": model_mae,\n",
    "            \"mape\": model_mape,\n",
    "            \"r2\": model_r2,\n",
    "        }\n",
    "        baseline_metrics = {\n",
    "            \"mse\": baseline_mse,\n",
    "            \"rmse\": baseline_rmse,\n",
    "            \"mae\": baseline_mae,\n",
    "            \"mape\": baseline_mape,\n",
    "            \"r2\": baseline_r2,\n",
    "        }\n",
    "        arima_metrics = {\n",
    "            \"mse\": arima_mse,\n",
    "            \"rmse\": arima_rmse,\n",
    "            \"mae\": arima_mae,\n",
    "            \"mape\": arima_mape,\n",
    "            \"r2\": arima_r2,\n",
    "        }\n",
    "        model_baseline_performance_metrics = {\n",
    "            \"mse\": round((baseline_mse / model_mse - 1) * 100, 2),\n",
    "            \"rmse\": round((baseline_rmse / model_rmse - 1) * 100, 2),\n",
    "            \"mae\": round((baseline_mae / model_mae - 1) * 100, 2),\n",
    "            \"mape\": round((baseline_mape / model_mape - 1) * 100, 2),\n",
    "            \"r2\": round((model_r2 / baseline_r2 - 1) * 100, 2),\n",
    "        }\n",
    "        model_arima_performance_metrics = {\n",
    "            \"mse\": round((arima_mse / model_mse - 1) * 100, 2),\n",
    "            \"rmse\": round((arima_rmse / model_rmse - 1) * 100, 2),\n",
    "            \"mae\": round((arima_mae / model_mae - 1) * 100, 2),\n",
    "            \"mape\": round((arima_mape / model_mape - 1) * 100, 2),\n",
    "            \"r2\": round((model_r2 / arima_r2 - 1) * 100, 2),\n",
    "        }\n",
    "\n",
    "        metrics_table = wandb.Table(columns=[\"metric\", \"model\", \"baseline\", \"arima\", \"model-baseline performance comparison [%]\", \n",
    "                                             \"model-arima performance comparison [%]\"])\n",
    "        for metric in model_metrics.keys():\n",
    "            metrics_table.add_data(metric, model_metrics[metric], baseline_metrics[metric], arima_metrics[metric], \n",
    "                                   model_baseline_performance_metrics[metric], model_arima_performance_metrics[metric])\n",
    "        wandb.log({\"metrics\": metrics_table})\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Setting a pytorch seed allows our model to always start with the same initial weights and biases\n",
    "    seed_value = 42\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "    wandb_logger = WandbLogger(project=\"RNN_single_step_forecasts\", log_model=\"all\", config=wandb_config)\n",
    "    # train_loader, val_loader, test_loader, label_scaler, test_dates = load_data()\n",
    "    \n",
    "    module = StockPredictionModule(model=model, label_scaler=label_scaler,\n",
    "                                   train_loader=train_loader, val_loader=val_loader, test_loader=test_loader, test_dates = test_dates)\n",
    "\n",
    "    # Device agnostic initialization\n",
    "    if torch.cuda.is_available():   # Check for GPU availability\n",
    "        accelerator = \"gpu\"\n",
    "        devices = 1\n",
    "    elif hasattr(torch, 'has_mps') and torch.backends.mps.is_built():  # Check for MPS availability (Apple Silicon)\n",
    "        accelerator = \"mps\"\n",
    "        devices = 1\n",
    "    else:\n",
    "        accelerator = None  # Defaults to CPU\n",
    "        devices = None  # Ignored for CPU\n",
    "\n",
    "    trainer = Trainer(max_epochs=num_epochs, logger=wandb_logger, accelerator=accelerator, devices=devices, enable_checkpointing=True)\n",
    "    trainer.fit(module, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    trainer.test(dataloaders=test_loader, ckpt_path=\"best\")\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch\n",
    "from models import LSTM\n",
    "from config import model_config, device\n",
    "from preprocessing import train_loader, val_loader, label_scaler\n",
    "import wandb\n",
    "\n",
    "class StockPredictionModule(LightningModule):\n",
    "    def __init__(self, model, label_scaler, train_loader, val_loader, test_loader, test_dates):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.label_scaler = label_scaler\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.test_dates = test_dates\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        seqs, labels = batch\n",
    "        y_pred = self(seqs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "def objective(trial):\n",
    "    # Ensure wandb is properly initialized\n",
    "    wandb.init(project=\"optuna_hyperparameter_tuning\", entity=\"frederik135\", reinit=True)\n",
    "    \n",
    "    # Define hyperparameters to tune\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 16, 128)\n",
    "    dropout_prob = trial.suggest_uniform('dropout_prob', 0.0, 0.5)\n",
    "\n",
    "    # Update model configuration\n",
    "    model_config.update({\n",
    "        \"hidden_layer_size\": hidden_size,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"dropout_prob\": dropout_prob\n",
    "    })\n",
    "\n",
    "    # Create the model with new hyperparameters\n",
    "    model = LSTM(**model_config).to(device)\n",
    "\n",
    "    # Instantiate the PyTorch Lightning module\n",
    "    module = StockPredictionModule(model=model, label_scaler=label_scaler,\n",
    "                                   train_loader=train_loader, val_loader=val_loader, test_loader=None, test_dates=None)\n",
    "    module.hparams.learning_rate = learning_rate\n",
    "\n",
    "    # Device agnostic initialization\n",
    "    if torch.cuda.is_available():\n",
    "        accelerator = \"gpu\"\n",
    "        devices = 1\n",
    "    elif hasattr(torch, 'has_mps') and torch.backends.mps.is_built():\n",
    "        accelerator = \"mps\"\n",
    "        devices = 1\n",
    "    else:\n",
    "        accelerator = None\n",
    "        devices = None\n",
    "\n",
    "    # Trainer setup with Wandb Logger\n",
    "    wandb_logger = WandbLogger(project=\"optuna_hyperparameter_tuning\", log_model=\"all\")\n",
    "    trainer = Trainer(\n",
    "        logger=wandb_logger,\n",
    "        max_epochs=50,\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        enable_checkpointing=False,  # Assuming you want to disable checkpointing\n",
    "        enable_progress_bar=False    # Correct parameter to control the progress bar visibility\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    trainer.fit(module, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_result = trainer.validate(module, dataloaders=val_loader, verbose=False)\n",
    "    if val_result:  # Check if result is not empty\n",
    "        val_loss = val_result[0].get('val_loss')\n",
    "        if val_loss is None:\n",
    "            print(\"Key 'val_loss' not found in the result. Available keys:\", val_result[0].keys())\n",
    "    else:\n",
    "        print(\"Validation result is empty.\")\n",
    "        val_loss = float('inf')  # or handle as appropriate\n",
    "\n",
    "    # Ensure wandb run is ended after each trial\n",
    "    wandb.finish()\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best hyperparameters: \", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters: \", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
