LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name      | Type     | Params
---------------------------------------
0 | model     | RNNModel | 2.3 K
1 | criterion | MSELoss  | 0
---------------------------------------
2.3 K     Trainable params
0         Non-trainable params
2.3 K     Total params
0.009     Total estimated model params size (MB)
c:\Users\janfr\anaconda3\envs\pytorch_3_10\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.
Sanity Checking: |          | 0/? [00:00<?, ?it/s]
c:\Users\janfr\anaconda3\envs\pytorch_3_10\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.


Epoch 0: 100%|██████████| 48/48 [00:04<00:00, 10.61it/s, v_num=12wl, train_loss_step=0.181]



Epoch 1: 100%|██████████| 48/48 [00:05<00:00,  9.39it/s, v_num=12wl, train_loss_step=0.174, val_loss_step=0.0667, val_loss_epoch=0.0708, train_loss_epoch=0.0694]



Epoch 2: 100%|██████████| 48/48 [00:05<00:00,  9.00it/s, v_num=12wl, train_loss_step=0.171, val_loss_step=0.0671, val_loss_epoch=0.0702, train_loss_epoch=0.066]



Epoch 3: 100%|██████████| 48/48 [00:05<00:00,  8.63it/s, v_num=12wl, train_loss_step=0.168, val_loss_step=0.067, val_loss_epoch=0.0703, train_loss_epoch=0.0658]



Epoch 4: 100%|██████████| 48/48 [00:05<00:00,  8.64it/s, v_num=12wl, train_loss_step=0.165, val_loss_step=0.067, val_loss_epoch=0.0702, train_loss_epoch=0.0656]




Epoch 5: 100%|██████████| 48/48 [00:05<00:00,  8.39it/s, v_num=12wl, train_loss_step=0.161, val_loss_step=0.0668, val_loss_epoch=0.0703, train_loss_epoch=0.0655]



Epoch 6: 100%|██████████| 48/48 [00:05<00:00,  8.54it/s, v_num=12wl, train_loss_step=0.156, val_loss_step=0.0667, val_loss_epoch=0.0703, train_loss_epoch=0.0654]



Epoch 7: 100%|██████████| 48/48 [00:05<00:00,  8.18it/s, v_num=12wl, train_loss_step=0.151, val_loss_step=0.0667, val_loss_epoch=0.0704, train_loss_epoch=0.0653]



Epoch 8: 100%|██████████| 48/48 [00:05<00:00,  8.42it/s, v_num=12wl, train_loss_step=0.146, val_loss_step=0.0666, val_loss_epoch=0.0705, train_loss_epoch=0.0652]



Epoch 9: 100%|██████████| 48/48 [00:05<00:00,  8.52it/s, v_num=12wl, train_loss_step=0.141, val_loss_step=0.0665, val_loss_epoch=0.0706, train_loss_epoch=0.0651]



Epoch 10: 100%|██████████| 48/48 [00:06<00:00,  7.76it/s, v_num=12wl, train_loss_step=0.135, val_loss_step=0.0664, val_loss_epoch=0.0707, train_loss_epoch=0.065]


Epoch 11: 100%|██████████| 48/48 [00:05<00:00,  8.00it/s, v_num=12wl, train_loss_step=0.130, val_loss_step=0.0662, val_loss_epoch=0.0708, train_loss_epoch=0.0649]



Epoch 12: 100%|██████████| 48/48 [00:06<00:00,  7.86it/s, v_num=12wl, train_loss_step=0.126, val_loss_step=0.0659, val_loss_epoch=0.0708, train_loss_epoch=0.0649]



Epoch 13: 100%|██████████| 48/48 [00:05<00:00,  8.02it/s, v_num=12wl, train_loss_step=0.122, val_loss_step=0.0656, val_loss_epoch=0.0709, train_loss_epoch=0.0648]



Epoch 14: 100%|██████████| 48/48 [00:07<00:00,  6.65it/s, v_num=12wl, train_loss_step=0.118, val_loss_step=0.0653, val_loss_epoch=0.0709, train_loss_epoch=0.0647]



Epoch 15: 100%|██████████| 48/48 [00:06<00:00,  7.37it/s, v_num=12wl, train_loss_step=0.115, val_loss_step=0.065, val_loss_epoch=0.071, train_loss_epoch=0.0647]



Epoch 16: 100%|██████████| 48/48 [00:06<00:00,  7.77it/s, v_num=12wl, train_loss_step=0.111, val_loss_step=0.0647, val_loss_epoch=0.071, train_loss_epoch=0.0646]



Epoch 17: 100%|██████████| 48/48 [00:06<00:00,  7.74it/s, v_num=12wl, train_loss_step=0.108, val_loss_step=0.0645, val_loss_epoch=0.071, train_loss_epoch=0.0645]



Epoch 18: 100%|██████████| 48/48 [00:06<00:00,  7.34it/s, v_num=12wl, train_loss_step=0.104, val_loss_step=0.0644, val_loss_epoch=0.071, train_loss_epoch=0.0644]



Epoch 19: 100%|██████████| 48/48 [00:06<00:00,  7.94it/s, v_num=12wl, train_loss_step=0.100, val_loss_step=0.0642, val_loss_epoch=0.071, train_loss_epoch=0.0643]



Epoch 20: 100%|██████████| 48/48 [00:05<00:00,  8.25it/s, v_num=12wl, train_loss_step=0.0965, val_loss_step=0.0641, val_loss_epoch=0.0711, train_loss_epoch=0.0642]




Epoch 21: 100%|██████████| 48/48 [00:05<00:00,  8.11it/s, v_num=12wl, train_loss_step=0.0926, val_loss_step=0.064, val_loss_epoch=0.0711, train_loss_epoch=0.0641]



Epoch 22: 100%|██████████| 48/48 [00:05<00:00,  8.27it/s, v_num=12wl, train_loss_step=0.0887, val_loss_step=0.0639, val_loss_epoch=0.0712, train_loss_epoch=0.064]



Epoch 23: 100%|██████████| 48/48 [00:05<00:00,  8.15it/s, v_num=12wl, train_loss_step=0.0846, val_loss_step=0.0637, val_loss_epoch=0.0713, train_loss_epoch=0.0639]



Epoch 24: 100%|██████████| 48/48 [00:05<00:00,  8.28it/s, v_num=12wl, train_loss_step=0.0804, val_loss_step=0.0636, val_loss_epoch=0.0714, train_loss_epoch=0.0638]



Epoch 25: 100%|██████████| 48/48 [00:05<00:00,  8.17it/s, v_num=12wl, train_loss_step=0.0762, val_loss_step=0.0634, val_loss_epoch=0.0715, train_loss_epoch=0.0637]


Epoch 26: 100%|██████████| 48/48 [00:05<00:00,  8.14it/s, v_num=12wl, train_loss_step=0.072, val_loss_step=0.0633, val_loss_epoch=0.0716, train_loss_epoch=0.0636]



Epoch 27: 100%|██████████| 48/48 [00:06<00:00,  7.92it/s, v_num=12wl, train_loss_step=0.0678, val_loss_step=0.0631, val_loss_epoch=0.0718, train_loss_epoch=0.0634]



Epoch 28: 100%|██████████| 48/48 [00:05<00:00,  8.39it/s, v_num=12wl, train_loss_step=0.0638, val_loss_step=0.0629, val_loss_epoch=0.0719, train_loss_epoch=0.0633]



Epoch 29: 100%|██████████| 48/48 [00:05<00:00,  8.18it/s, v_num=12wl, train_loss_step=0.0598, val_loss_step=0.0627, val_loss_epoch=0.0721, train_loss_epoch=0.0631]

`Trainer.fit` stopped: `max_epochs=30` reached.
Restoring states from the checkpoint path at .\RNN_single_step_forecasts\jrl512wl\checkpoints\epoch=29-step=1440.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at .\RNN_single_step_forecasts\jrl512wl\checkpoints\epoch=29-step=1440.ckpt
Epoch 29: 100%|██████████| 48/48 [00:11<00:00,  4.21it/s, v_num=12wl, train_loss_step=0.0598, val_loss_step=0.0626, val_loss_epoch=0.0723, train_loss_epoch=0.063]

Testing DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 90.40it/s]364
364
363
