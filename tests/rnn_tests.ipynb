{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_layer_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "    \n",
    "    def forward(self, input_seq):\n",
    "        rnn_out, _ = self.rnn(input_seq)\n",
    "        predictions = self.linear(rnn_out[:, -1])\n",
    "        return predictions\n",
    "    \n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=100):\n",
    "    for epoch in range(num_epochs):\n",
    "        for seqs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seqs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} Loss: {loss.item()}')\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        predictions, actuals = [], []\n",
    "        for seqs, labels in test_loader:\n",
    "            output = model(seqs)\n",
    "            predictions.extend(output.view(-1).tolist())\n",
    "            actuals.extend(labels.view(-1).tolist())\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    return predictions, actuals\n",
    "\n",
    "# Function to perform the training process\n",
    "def train_and_validate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training step\n",
    "        model.train()\n",
    "        for seqs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seqs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for seqs, labels in val_loader:\n",
    "                y_pred = model(seqs)\n",
    "                loss = criterion(y_pred, labels)\n",
    "                val_losses.append(loss.item())\n",
    "        val_loss = np.mean(val_losses)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Training Loss: {loss.item()} | Validation Loss: {val_loss}')\n",
    "\n",
    "def plot_predictions(model, loader, scaler):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for seqs, labels in loader:\n",
    "            preds = model(seqs)  # Predict\n",
    "            # Inverse transform predictions and actual labels\n",
    "            preds = scaler.inverse_transform(preds.cpu().numpy()).flatten().tolist()\n",
    "            labels = scaler.inverse_transform(labels.cpu().numpy()).flatten().tolist()\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(labels)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(actuals, label='Actual Price', color='blue', marker='o')\n",
    "    plt.plot(predictions, label='Predicted Price', color='red', linestyle='--')\n",
    "    plt.title('Apple Stock Price Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Parameters\n",
    "seq_length = 5\n",
    "input_size = 1\n",
    "hidden_layer_size = 50\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "aapl_df = yf.download('AAPL', start='2018-01-01', end='2024-01-15')\n",
    "aapl_df[['Close']]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data_normalized = scaler.fit_transform(aapl_df.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 5\n",
    "X, y = create_sequences(data_normalized, seq_length)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert to tensors and create DataLoader for batch processing\n",
    "train_data = torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "val_data = torch.utils.data.TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model initialization\n",
    "model = RNNModel(input_size, hidden_layer_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train and validate the model\n",
    "train_and_validate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "# Forecasting future stock prices\n",
    "# For a simple demonstration, let's predict the next day's price using the latest data from X_test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    last_sequence = torch.FloatTensor(X_test[-1:]).to(torch.float32)  # Last sequence from the test set\n",
    "    predicted_normalized_price = model(last_sequence).item()  # Model's prediction\n",
    "    predicted_price = scaler.inverse_transform([[predicted_normalized_price]])[0][0]  # Inverse transform to get the actual price\n",
    "    print(f'Predicted Price: {predicted_price}')\n",
    "\n",
    "plot_predictions(model, val_loader, scaler)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_layer_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "    \n",
    "    def forward(self, input_seq):\n",
    "        rnn_out, _ = self.rnn(input_seq)\n",
    "        predictions = self.linear(rnn_out[:, -1])\n",
    "        return predictions\n",
    "    \n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=100):\n",
    "    for epoch in range(num_epochs):\n",
    "        for seqs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seqs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} Loss: {loss.item()}')\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        predictions, actuals = [], []\n",
    "        for seqs, labels in test_loader:\n",
    "            output = model(seqs)\n",
    "            predictions.extend(output.view(-1).tolist())\n",
    "            actuals.extend(labels.view(-1).tolist())\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    return predictions, actuals\n",
    "\n",
    "def train_and_validate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training step\n",
    "        model.train()\n",
    "        for seqs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seqs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for seqs, labels in val_loader:\n",
    "                y_pred = model(seqs)\n",
    "                loss = criterion(y_pred, labels)\n",
    "                val_losses.append(loss.item())\n",
    "        val_loss = np.mean(val_losses)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Training Loss: {loss.item()} | Validation Loss: {val_loss}')\n",
    "\n",
    "'''\n",
    "def plot_predictions(model, loader, scaler, y_test):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for seqs, labels in loader:\n",
    "            preds = model(seqs)  # Predict\n",
    "            # Inverse transform predictions and actual labels\n",
    "            preds = scaler.inverse_transform(preds.cpu().numpy()).flatten().tolist()\n",
    "            labels = scaler.inverse_transform(labels.cpu().numpy()).flatten().tolist()\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(labels)\n",
    "\n",
    "    print(y_test)\n",
    "    \n",
    "    dates = aapl_df.index[-len(y_test):]  # This assumes y_test is not shuffled and is in order\n",
    "\n",
    "    def plot_predictions_with_dates(predictions, actuals, dates):\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.plot(dates, actuals, label='Actual Price', color='blue', marker='o')\n",
    "        plt.plot(dates, predictions, label='Predicted Price', color='red', linestyle='--')\n",
    "        plt.title('Apple Stock Price Prediction')\n",
    "        plt.xlabel('Date')\n",
    "        plt.xticks(rotation=45)  # Rotate dates for better readability\n",
    "        plt.ylabel('Stock Price')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()  # Adjust layout to fit date labels\n",
    "        plt.show()\n",
    "\n",
    "    plot_predictions_with_dates(predictions, actuals, dates)\n",
    "'''\n",
    "    \n",
    "def plot_predictions_with_dates(predictions, actuals, dates):\n",
    "    # Sort by dates\n",
    "    sorted_indices = np.argsort(dates)\n",
    "    sorted_dates = dates[sorted_indices]\n",
    "    sorted_predictions = np.array(predictions)[sorted_indices]\n",
    "    sorted_actuals = np.array(actuals)[sorted_indices]\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(sorted_dates, sorted_actuals, label='Actual Price', color='blue', marker='o')\n",
    "    plt.plot(sorted_dates, sorted_predictions, label='Predicted Price', color='red', linestyle='--')\n",
    "    plt.title('Apple Stock Price Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "seq_length = 5\n",
    "input_size = 1\n",
    "hidden_layer_size = 50\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "aapl_df = yf.download('AAPL', start='2018-01-01', end='2024-01-15')\n",
    "aapl_df = aapl_df[['Close']]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data_normalized = scaler.fit_transform(aapl_df.values.reshape(-1, 1))\n",
    "\n",
    "X, y = create_sequences(data_normalized, seq_length)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert to tensors and create DataLoader for batch processing\n",
    "train_data = torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "val_data = torch.utils.data.TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test, idx_temp, idx_test = train_test_split(\n",
    "    X, y, range(len(X)), test_size=0.2, random_state=42, shuffle=False\n",
    ")\n",
    "X_train, X_val, y_train, y_val, idx_train, idx_val = train_test_split(\n",
    "    X_temp, y_temp, idx_temp, test_size=0.25, random_state=42, shuffle=False\n",
    ")\n",
    "\n",
    "test_dates = aapl_df.iloc[idx_test].index\n",
    "test_data = torch.utils.data.TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "sorted_indices = np.argsort(test_dates)\n",
    "sorted_dates = test_dates[sorted_indices]\n",
    "\n",
    "X_test_sorted = X_test[sorted_indices]\n",
    "y_test_sorted = y_test[sorted_indices]\n",
    "\n",
    "test_data_sorted = torch.utils.data.TensorDataset(torch.FloatTensor(X_test_sorted), torch.FloatTensor(y_test_sorted))\n",
    "test_loader_sorted = torch.utils.data.DataLoader(dataset=test_data_sorted, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "model = RNNModel(input_size, hidden_layer_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_and_validate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    last_sequence = torch.FloatTensor(X_test[-1:]).to(torch.float32)\n",
    "    predicted_normalized_price = model(last_sequence).item()\n",
    "    predicted_price = scaler.inverse_transform([[predicted_normalized_price]])[0][0]\n",
    "    print(f'Predicted Price: {predicted_price}')\n",
    "\n",
    "\n",
    "plot_predictions_with_dates(predictions, actuals, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        xs.append(data[i:(i+seq_length)])\n",
    "        ys.append(data[i+seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout_prob):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_layer_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "    \n",
    "    def forward(self, input_seq):\n",
    "        rnn_out, _ = self.rnn(input_seq)\n",
    "        return self.linear(rnn_out[:, -1])\n",
    "\n",
    "def train_and_validate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for seqs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seqs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for seqs, labels in val_loader:\n",
    "                y_pred = model(seqs)\n",
    "                val_losses.append(criterion(y_pred, labels).item())\n",
    "        val_loss = np.mean(val_losses)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Training Loss: {loss.item()} | Validation Loss: {val_loss}')\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for seqs, labels in test_loader:\n",
    "            output = model(seqs)\n",
    "            predictions.extend(output.view(-1).tolist())\n",
    "            actuals.extend(labels.view(-1).tolist())\n",
    "    return np.array(predictions), np.array(actuals)\n",
    "\n",
    "def plot_predictions_with_dates(predictions, actuals, dates):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(dates, actuals, label='Actual Price', color='blue', marker='o')\n",
    "    plt.plot(dates, predictions, label='Predicted Price', color='red', linestyle='--')\n",
    "    plt.title('Stock Price Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Load data and split into training, validation and test set\n",
    "aapl_df = yf.download('AAPL', start='2005-01-01', end='2024-01-01')\n",
    "data_normalized = MinMaxScaler(feature_range=(-1, 1)).fit_transform(aapl_df[['Close']].values.reshape(-1, 1))\n",
    "X, y = create_sequences(data_normalized, seq_length=21)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Convert to tensors and create DataLoader for batch processing\n",
    "train_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train)), batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val)), batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test)), batch_size=64, shuffle=False)\n",
    "\n",
    "# Model initialization and training\n",
    "model = RNNModel(input_size=1, hidden_layer_size=100, num_layers=2, output_size=1, dropout_prob=0.25)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_and_validate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=200)\n",
    "\n",
    "# Evaluation\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "print(f'MSE: {mean_squared_error(actuals, predictions)}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(actuals, predictions))}')\n",
    "print(f'MAE: {mean_absolute_error(actuals, predictions)}')\n",
    "print(f'R-squared: {r2_score(actuals, predictions)}')\n",
    "\n",
    "# Plotting predictions\n",
    "plot_predictions_with_dates(predictions, actuals, aapl_df.index[-len(predictions):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite Code for RNN Model to make it device independent\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        xs.append(data[i:(i+seq_length)])\n",
    "        ys.append(data[i+seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout_prob):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_layer_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "    \n",
    "    def forward(self, input_seq):\n",
    "        rnn_out, _ = self.rnn(input_seq)\n",
    "        return self.linear(rnn_out[:, -1])\n",
    "\n",
    "def train_and_validate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for seqs, labels in train_loader:\n",
    "            seqs, labels = seqs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seqs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for seqs, labels in val_loader:\n",
    "                seqs, labels = seqs.to(device), labels.to(device)\n",
    "                y_pred = model(seqs)\n",
    "                val_losses.append(criterion(y_pred, labels).item())\n",
    "        val_loss = np.mean(val_losses)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Training Loss: {loss.item()} | Validation Loss: {val_loss}')\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for seqs, labels in test_loader:\n",
    "            seqs, labels = seqs.to(device), labels.to(device)\n",
    "            output = model(seqs)\n",
    "            predictions.extend(output.view(-1).tolist())\n",
    "            actuals.extend(labels.view(-1).tolist())\n",
    "    return np.array(predictions), np.array(actuals)\n",
    "\n",
    "def plot_predictions_with_dates(predictions, actuals, dates):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(dates, actuals, label='Actual Price', color='blue', marker='o')\n",
    "    plt.plot(dates, predictions, label='Predicted Price', color='red', linestyle='--')\n",
    "    plt.title('Stock Price Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data and split into training, validation and test set\n",
    "aapl_df = yf.download('AAPL', start='2005-01-01', end='2024-01-01')\n",
    "data_normalized = MinMaxScaler(feature_range=(-1, 1)).fit_transform(aapl_df[['Close']].values.reshape(-1, 1))\n",
    "X, y = create_sequences(data_normalized, seq_length=5)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Convert to tensors and create DataLoader for batch processing\n",
    "train_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train)), batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val)), batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test)), batch_size=64, shuffle=False)\n",
    "\n",
    "# Model initialization and training\n",
    "model = RNNModel(input_size=1, hidden_layer_size=50, num_layers=2, output_size=1, dropout_prob=0.2).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_and_validate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "# Evaluation\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "print(f'MSE: {mean_squared_error(actuals, predictions)}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(actuals, predictions))}')\n",
    "print(f'MAE: {mean_absolute_error(actuals, predictions)}')\n",
    "print(f'R-squared: {r2_score(actuals, predictions)}')\n",
    "\n",
    "# Plotting predictions\n",
    "plot_predictions_with_dates(predictions, actuals, aapl_df.index[-len(predictions):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
